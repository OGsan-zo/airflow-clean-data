Parfait ! ğŸ‘Œ On va **supprimer proprement l'ancienne installation** et ensuite **installer Airflow dans ton nouveau rÃ©pertoire propre** :

---

## ğŸ§¹ Ã‰TAPE 1 â€“ Supprimer lâ€™ancienne installation dâ€™Airflow

### ğŸ” 1.1 Trouver l'ancien environnement

Si tu avais un environnement `airflow_env` dans un rÃ©pertoire comme :

```
~/Documents/Studies/ITU/S6/Mr Naina/Airflow/TP/airflow_env/
```

Alors tu peux simplement **le supprimer** :

```bash
rm -rf ~/Documents/Studies/ITU/S6/Mr\ Naina/Airflow/TP/airflow_env
```

(âš ï¸ Le `\` sert Ã  gÃ©rer lâ€™espace dans `Mr Naina`)

Tu peux aussi supprimer le `AIRFLOW_HOME` de cette installation, sâ€™il existe :

```bash
rm -rf ~/airflow
```

### ğŸš« 1.2 VÃ©rifie que `airflow` nâ€™est plus globalement accessible

AprÃ¨s avoir dÃ©sactivÃ© tout environnement :

```bash
deactivate
which airflow
```

Si Ã§a ne retourne **rien**, câ€™est parfait. Sinon, on lâ€™a mal supprimÃ©.

---

## ğŸ—ï¸ Ã‰TAPE 2 â€“ Nouvelle installation dâ€™Airflow dans `~/Documents/Studies/ITU/S6/Serveur`

### ğŸ“ 2.1 CrÃ©e un dossier propre

```bash
cd ~/Documents/Studies/ITU/S6/Serveur
mkdir airflow_project
cd airflow_project
```

### ğŸ 2.2 CrÃ©e et active un environnement virtuel

```bash
python3 -m venv airflow_env
source airflow_env/bin/activate
```

---

## ğŸ“¥ Ã‰TAPE 3 â€“ Installation propre dâ€™Airflow

### ğŸ“Œ 3.1 DÃ©finir les variables dâ€™environnement

```bash
export AIRFLOW_VERSION=3.0.0
export PYTHON_VERSION="$(python3 -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')"
export CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
```

### âœ… 3.2 Installer Airflow avec contraintes officielles

```bash
pip install --upgrade pip
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

### ğŸ§© 3.3 Installer les providers SQL

```bash
pip install apache-airflow-providers-mysql apache-airflow-providers-postgres apache-airflow-providers-common-sql \
  --constraint "${CONSTRAINT_URL}"
```

---

## âš™ï¸ Ã‰TAPE 4 â€“ Initialiser Airflow

### ğŸ“ 4.1 DÃ©finir un `AIRFLOW_HOME` propre dans le projet

Toujours dans `airflow_project` :

```bash
export AIRFLOW_HOME=$(pwd)/airflow_home
```

Et crÃ©e les dossiers nÃ©cessaires :

```bash
mkdir -p $AIRFLOW_HOME/dags
```

### ğŸ› ï¸ 4.2 Initialiser la base de donnÃ©es Airflow

```bash
airflow db init
```

---

## ğŸ‘¤ Ã‰TAPE 5 â€“ CrÃ©er un utilisateur admin

```bash
airflow users create \
  --username admin \
  --firstname Zo \
  --lastname Kely \
  --role Admin \
  --email zo@example.com \
  --password admin
```

---

## ğŸš€ Ã‰TAPE 6 â€“ Lancer Airflow

### Dans un terminal :

```bash
airflow scheduler
```

### Dans un **autre** terminal :

```bash
source ~/Documents/Studies/ITU/S6/Serveur/airflow_project/airflow_env/bin/activate
export AIRFLOW_HOME=~/Documents/Studies/ITU/S6/Serveur/airflow_project/airflow_home
airflow webserver --port 8080
```

---

## ğŸ¯ RÃ©sultat attendu

* Tu vas pouvoir ouvrir [http://localhost:8080](http://localhost:8080)
* Tu verras tes DAGs dans la section dâ€™accueil.

---
